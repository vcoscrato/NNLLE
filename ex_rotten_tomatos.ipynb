{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-29 10:35:56--  http://www.cs.cornell.edu/People/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz [following]\n",
      "--2021-07-29 10:35:56--  http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
      "Reusing existing connection to www.cs.cornell.edu:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 487770 (476K) [application/x-gzip]\n",
      "Saving to: ‘data/rt-polaritydata.tar.gz’\n",
      "\n",
      "rt-polaritydata.tar 100%[===================>] 476.34K   512KB/s    in 0.9s    \n",
      "\n",
      "2021-07-29 10:35:57 (512 KB/s) - ‘data/rt-polaritydata.tar.gz’ saved [487770/487770]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'http://www.cs.cornell.edu/People/pabo/movie-review-data/rt-polaritydata.tar.gz' -P 'data'\n",
    "!tar -xf data/rt-polaritydata.tar.gz -C 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('while the performances are often engaging , this loose collection of largely improvised numbers would probably have worked better as a one-hour tv documentary .',\n",
       " 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ = './data/rt-polaritydata/'\n",
    "def load_polarity(path=path_):\n",
    "    data = []\n",
    "    labels = []\n",
    "    f_names = ['rt-polarity.neg', 'rt-polarity.pos']\n",
    "    for (l, f) in enumerate(f_names):\n",
    "        for line in open(os.path.join(path, f), 'rb'):\n",
    "            data.append(line.decode('utf8', errors='ignore').strip())\n",
    "            labels.append(l)\n",
    "    return data, labels\n",
    "\n",
    "x_d, y = load_polarity()\n",
    "\n",
    "x_d[11], y[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'performance often engaging loose collection largely improvised number would probably worked better onehour tv documentary'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct = str.maketrans('', '', string.punctuation)\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "stops = stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "def process_text(sentence):\n",
    "    out = sentence.lower()\n",
    "    out = out.translate(remove_punct)\n",
    "    out = out.translate(remove_digits)\n",
    "    out = [wnl.lemmatize(w) for w in out.split() if w not in stops]\n",
    "    return ' '.join(out)\n",
    "\n",
    "x = []\n",
    "for x_i in x_d[:]:\n",
    "    x.append(process_text(x_i))\n",
    "    \n",
    "x[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all_d, x_test_d, y_train_all_d, y_test_d = train_test_split(\n",
    "    x_d, y, test_size=.2, random_state=42)\n",
    "x_train_d, x_val_d, y_train_d, y_val_d = train_test_split(\n",
    "    x_train_all_d, y_train_all_d, test_size=.1, random_state=42)\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    x, y, test_size=.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_all, y_train_all, test_size=.1, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['act', 'acted', 'acting', 'action', 'actor', 'actress', 'actually',\n",
       "        'adaptation', 'add', 'adult'], dtype='<U14'),\n",
       " 523)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorizeText():\n",
    "    def __init__(self, limit=True, **kwargs):\n",
    "      if limit:\n",
    "        self.count_vect = CountVectorizer(min_df=0.003, max_df=0.997, **kwargs)\n",
    "      else:\n",
    "        self.count_vect = CountVectorizer(**kwargs)\n",
    "      self.tf_transformer = TfidfTransformer(use_idf=False)\n",
    "    def fit(self, x):\n",
    "        x = self.count_vect.fit_transform(x)\n",
    "        self.tf_transformer.fit(x)\n",
    "    def transform(self, x):\n",
    "        x = self.count_vect.transform(x)\n",
    "        x = self.tf_transformer.transform(x)\n",
    "        return x.toarray()     \n",
    "    def get_feature_names(self):\n",
    "        return vectorizer.count_vect.get_feature_names()\n",
    "    \n",
    "vectorizer = VectorizeText(limit=True) # max_features=500)\n",
    "#vectorizer = VectorizeText(limit=True, stop_words='english')\n",
    "vectorizer.fit(x_train)    \n",
    "x_vec_train = vectorizer.transform(x_train)\n",
    "x_vec_test = vectorizer.transform(x_test)\n",
    "\n",
    "names_features = np.array(vectorizer.get_feature_names())\n",
    "names_features[:10], len(names_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
